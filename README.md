# Dominus AI - Advanced AI Service Infrastructure

An independent AI service infrastructure providing context-aware LLM capabilities, RAG (Retrieval Augmented Generation), and extensible knowledge management.

## ğŸš€ Overview

Dominus AI is a sophisticated standalone AI service that provides:
- **GPT-OSS-120B** model deployment via Ollama (65GB, 8K context)
- **Context-aware conversations** with session persistence
- **RAG system** with ChromaDB for document retrieval
- **TGI-compatible REST API** bridge
- **Extensible plugin architecture** for future capabilities

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     DOMINUS AI PLATFORM                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   Ollama    â”‚  â”‚   Context   â”‚  â”‚     RAG     â”‚      â”‚
â”‚  â”‚  GPT-OSS    â”‚â—„â”€â”¤   Manager   â”œâ”€â–ºâ”‚   Engine    â”‚      â”‚
â”‚  â”‚    120B     â”‚  â”‚  (SQLite)   â”‚  â”‚ (ChromaDB)  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â–²                â”‚                 â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                          â–¼                                â”‚
â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚               â”‚  Context Bridge  â”‚                        â”‚
â”‚               â”‚   (Port 8090)    â”‚                        â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                          â”‚                                â”‚
â”‚                          â–¼                                â”‚
â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚               â”‚   NGINX Proxy    â”‚                        â”‚
â”‚               â”‚  (Port 8001 SSL) â”‚                        â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                          â”‚                                â”‚
â”‚                          â–¼                                â”‚
â”‚                  External Clients                         â”‚
â”‚            (darkfoo.com, other services)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
/home/ken/ai/dominus-ai/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ context_bridge.py      # Main API server with context awareness
â”‚   â”œâ”€â”€ context_manager.py     # Session and conversation management
â”‚   â”œâ”€â”€ rag_engine.py          # RAG system with ChromaDB
â”‚   â””â”€â”€ document_ingestion.py  # Document processing pipeline (coming)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ chromadb/              # Vector database storage
â”‚   â”œâ”€â”€ sessions.db            # SQLite conversation history
â”‚   â””â”€â”€ cache/                 # Embedding cache
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ bridge.log             # Service logs
â”‚   â””â”€â”€ bridge-error.log       # Error logs
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ PHASE3_RAG_ARCHITECTURE.md  # RAG system design
â””â”€â”€ scripts/
    â””â”€â”€ start-services.sh      # Service management scripts
```

## ğŸ”Œ Core Services

### Context Bridge (`context_bridge.py`)
- **Port**: 8090
- **Features**: Context-aware conversations, session management, RAG integration
- **Endpoints**: `/chat`, `/generate`, `/session/*`, `/health`

### Context Manager (`context_manager.py`)
- **Storage**: SQLite database
- **Features**: Session persistence, conversation history, token tracking
- **Capacity**: Unlimited sessions with automatic cleanup

### RAG Engine (`rag_engine.py`)
- **Vector DB**: ChromaDB with persistent storage
- **Embeddings**: sentence-transformers (all-MiniLM-L6-v2)
- **Features**: Document chunking, semantic search, collection management

### Network Configuration
- **Port 8090**: Internal bridge service (TGI-compatible API)
- **Port 11434**: Ollama native API
- **Port 8001**: Public HTTPS endpoint (via nginx proxy)

## Installation

1. Install Ollama:
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

2. Pull the model:
```bash
ollama pull gpt-oss:120b
```

3. Install Python dependencies:
```bash
pip install -r requirements.txt
```

4. Start services:
```bash
./scripts/start-services.sh
```

## API Usage

### Generate Text
```bash
curl -X POST https://api.darkfoo.com:8001/generate \
  -H "Content-Type: application/json" \
  -d '{
    "inputs": "Hello, how are you?",
    "parameters": {
      "max_new_tokens": 100,
      "temperature": 0.7
    }
  }'
```

### Health Check
```bash
curl https://api.darkfoo.com:8001/health
```

## Development

This project is designed to be service-agnostic and can be integrated with any application requiring LLM capabilities.

### Directory Structure
```
dominus-ai/
â”œâ”€â”€ services/       # Core service implementations
â”œâ”€â”€ configs/        # Configuration files
â”œâ”€â”€ scripts/        # Utility and deployment scripts
â”œâ”€â”€ models/         # Model-specific configurations
â”œâ”€â”€ logs/          # Service logs
â””â”€â”€ docs/          # Documentation
```

## License

MIT

## Author

Ken - 2025